# -*- coding: utf-8 -*-
"""Assignment4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sck-yn_41dSeHsAt-zVuRwWL1J4k-qto

Assignemnt 4: TSP with GNNs

Morgan Pallas, Aylene McEntire, Jack Keim
"""

#installing torch
!pip install torch
import torch
print(f"PyTorch version: {torch.__version__}")

!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.6.0+cu124.html

!pip install torch-geometric

pip install dwave-ocean-sdk

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch_geometric.data import Data
from torch_geometric.nn import GCNConv
import math
from torch.utils.data import Dataset, DataLoader
import networkx as nx
import matplotlib.pyplot as plt
import dimod
from dwave.system import DWaveSampler, EmbeddingComposite
from itertools import product
import random

def haversine(coord1, coord2):
    # Coordinates in (latitude, longitude)
    lat1, lon1 = coord1
    lat2, lon2 = coord2
    R = 6371.0  # Earth radius in kilometers
    phi1, phi2 = np.radians(lat1), np.radians(lat2)
    dphi = np.radians(lat2 - lat1)
    dlambda = np.radians(lon2 - lon1)
    a = np.sin(dphi/2.0)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda/2.0)**2
    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
    return R * c  # in kilometers

#define the list of locations with their names and coordinates
locations = [
    ("Charleston, SC", (32.7765, -79.9311)),
    ("Mount Pleasant, SC", (32.8325, -79.8577)),
    ("Sullivan’s Island, SC", (32.6680, -79.9743)),
    ("Isle of Palms, SC", (32.7524, -79.8431)),
    ("James Island, SC", (32.7632, -79.9788)),
    ("West Ashley, SC", (32.8460, -80.0375)),
    ("Summerville, SC", (33.0181, -80.1756)),
    ("North Charleston, SC", (32.8781, -80.0043)),
    ("Hanahan, SC", (32.7870, -80.0077)),
    ("Moncks Corner, SC", (33.1670, -79.9765)),
    ("Ladson, SC", (32.9265, -80.0836)),
    ("Goose Creek, SC", (32.9812, -80.0724)),
    ("Charleston Neck, SC", (32.9000, -80.1000)),
    ("West Columbia, SC", (33.9950, -81.0498)),
    ("Columbia, SC", (34.0007, -81.0348)),
    ("Lexington, SC", (33.9857, -81.2235)),
    ("Irmo, SC", (34.0101, -81.0867)),
    ("St. Andrews, SC", (33.9001, -80.2500)),
    ("Fort Mill, SC", (34.9871, -80.9698)),
    ("Rock Hill, SC", (34.9249, -81.0251)),
    ("Concord, NC", (35.4087, -80.5795)),
    ("Gastonia, NC", (35.2621, -81.1873)),
    ("Mount Holly, NC", (35.2790, -81.0608)),
    ("Belmont, NC", (35.3435, -81.0550)),
    ("Davidson, NC", (35.4881, -80.8766)),
    ("Huntersville, NC", (35.4107, -80.8428)),
    ("Cornelius, NC", (35.4241, -80.8700)),
    ("Conover, NC", (35.4521, -80.8200)),
    ("Highland, NC", (35.4437, -80.8800)),
    ("Charlotte, NC", (35.2271, -80.8431))
]
# Count the number of nodes (locations) from the locations list
num_nodes = len(locations)                   # Total number of locations

# Create node features: Here we simply use the latitude and longitude as features
node_features = []                           # Initialize an empty list for node features
for name, (lat, lon) in locations:           # Iterate over each location
    node_features.append([lat, lon])         # Append the coordinates as a feature vector for the node
node_features = torch.tensor(node_features, dtype=torch.float)  # Convert the list into a PyTorch tensor# Build the graph by defining the edges and their attributes (distances)
edge_index = [[], []]                        # Initialize empty lists for the source and target node indices
edge_attr = []                               # Initialize an empty list for edge attributes (distances)

# Create a fully connected graph (each pair of different nodes is connected)
for i in range(num_nodes):                   # For each node i
    for j in range(num_nodes):               # For each node j
        if i != j:                         # Exclude self-loops (i should not equal j)
            edge_index[0].append(i)          # Add i as a source node index
            edge_index[1].append(j)          # Add j as a target node index
            # Compute the distance between node i and node j using the Haversine function
            d = haversine(locations[i][1], locations[j][1])
            edge_attr.append([d])            # Append the distance as an attribute (wrapped in a list)
# Convert the edge_index and edge_attr lists into PyTorch tensors
edge_index = torch.tensor(edge_index, dtype=torch.long)  # Tensor of shape [2, num_edges]
edge_attr = torch.tensor(edge_attr, dtype=torch.float)   # Tensor of shape [num_edges, 1]

# Create a PyTorch Geometric Data object to hold the graph information
data = Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)

"""Improvements: GNN;Adding batch normalization after each convolutional layer to stabilize learning. Maybe incorporating edge features (distances) more directly into the message passing. Using models like EdgeConvo or GATConv can better leverage edge information.

Imporovements: in the forward method, add dropout for regualtion. Could also use residual connections between GCN layers to help with gradient flow.
"""

# Define the Graph Neural Network (GNN) model for TSP using PyTorch
class TSP_GNN(nn.Module):
    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.3):
        # Initialize the parent class (nn.Module)
        super(TSP_GNN, self).__init__()
        # Define the first graph convolutional layer: maps from input features to hidden representation
        self.conv1 = GCNConv(in_channels, hidden_channels)
        # Define the second graph convolutional layer: further processes the hidden representation
        self.conv2 = GCNConv(hidden_channels, hidden_channels)
        # IMPROVEMENT: Define the third graph convolutional layer: gives the model more depth to reason over longer-range connections
        self.conv3 = GCNConv(hidden_channels, hidden_channels)
        # IMPROVEMENT: A dropout layer to reduce overfitting
        self.dropout = nn.Dropout(dropout)
        # A linear layer to produce a score for each node that can be used to select the next city
        self.linear = nn.Linear(hidden_channels, out_channels)

    def forward(self, data, state):
        # Unpack the data into node features (x), edge index, and edge attributes
        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr
        # Concatenate the state representation with the node features
        state = state.unsqueeze(1)  # Ensure state has the correct dimension
        x = torch.cat([x, state], dim=1)  # Concatenate along the feature dimension

        # Pass the node features through the first GCN layer
        x = self.conv1(x, edge_index)
        # Apply the ReLU activation function to add non-linearity
        x = torch.relu(x)
        # IMPROVEMENT: Add dropout
        x = self.dropout(x)

        # Pass the output through the second GCN layer
        x = self.conv2(x, edge_index)
        # Apply ReLU again
        x = torch.relu(x)
        # IMPROVEMENT: Added dropout
        x = self.dropout(x)

        # IMPROVEMENT: Third GCN layer + activation + dropout
        x = self.conv3(x, edge_index)
        x = torch.relu(x)
        x = self.dropout(x)

        # Use the linear layer to compute a score for each node based on its embedding
        scores = self.linear(x)

        # Return both the scores and the final node embeddings
        return scores, x

# Instantiate the model with the following parameters:
# - in_channels: 2 (latitude and longitude)
# - hidden_channels: 32 (number of hidden units in the GCN layers)
# - out_channels: 1 (a single score per node)
model = TSP_GNN(in_channels=3, hidden_channels=32, out_channels=1)

"""### GNN Theory and Why It Works for TSP
Graph Neural Networks are built to handle graph-structured data, making them a natural fit for the Traveling Salesman Problem, where each city is a node and distances are edges. GNNs work by passing messages between nodes- each node updates its representation by aggregating information from its neighbors. After a few layers of this, each node has a learned embedding that reflects both its own features and its position in the graph. This is exactly what TSP needs: city embeddings that capture spatial relationships. Once these embeddings are computed, they can be used to decide which city to visit next.

### Forward Method
The forward method is where the model processes the graph. It takes in node features, edge connections, and edge attributes, and runs them through three GCNConv layers with ReLU activations in between. Each layer allows the nodes to learn from a wider neighborhood. After the final layer, a linear layer outputs a score for each node, representing how strong of a candidate it is to be the next city in the tour. The method returns both the scores and final embeddings- compact, clean, and effective for route prediction.

### Model Improvements and Justification
While the base GNN works well, I added a few improvements to help it generalize better and handle more complex tours. First, I introduced dropout after each activation to reduce overfitting and encourage more robust learning. Second, I added a third GCN layer to give the model deeper capacity- this helps each node learn from a larger portion of the graph. Finally, while we didn't use edge features directly yet, future improvements could include edge-aware architectures like Graph Attention Networks or EdgeConv, allowing the model to reason more directly about inter-city distances. These tweaks help the model form a better understanding of the graph, ideally leading to smarter, more efficient tours.
"""

def nearest_neighbor_tour(locations, use_random_restart=True, use_two_opt=True):
    num_nodes = len(locations)
    visited = [False] * num_nodes
    best_tour = None
    best_distance = float('inf')

    def calculate_total_distance(tour):
        total_distance = 0
        for i in range(1, len(tour)):
            total_distance += haversine(locations[tour[i-1]][1], locations[tour[i]][1])
        return total_distance

    def two_opt(tour):
        # Perform a 2-opt swap: Swap two edges to try to improve the tour.
        for i in range(1, len(tour) - 2):
            for j in range(i + 1, len(tour) - 1):
                if j - i == 1: continue
                new_tour = tour[:]
                new_tour[i:j] = reversed(new_tour[i:j])
                if calculate_total_distance(new_tour) < calculate_total_distance(tour):
                    tour = new_tour
        return tour

    # Perform multiple restarts if random restart is enabled.
    for _ in range(10):  # 10 random restarts to explore different solutions
        # Initialize visited and tour
        visited = [False] * num_nodes
        tour = []
        current = random.randint(0, num_nodes - 1)  # Start from a random node if random restart is enabled
        visited[current] = True
        tour.append(current)

        # Construct the nearest neighbor tour
        while len(tour) < num_nodes:
            nearest = None
            min_distance = float('inf')

            for i in range(num_nodes):
                if not visited[i]:
                    distance = haversine(locations[current][1], locations[i][1])
                    if distance < min_distance:
                        min_distance = distance
                        nearest = i

            tour.append(nearest)
            visited[nearest] = True
            current = nearest

        # Return to the start node to complete the tour
        tour.append(tour[0])

        # Apply Two-Opt improvement if enabled
        if use_two_opt:
            tour = two_opt(tour)

        # Calculate the total distance of this tour
        total_distance = calculate_total_distance(tour)

        # Track the best tour found
        if total_distance < best_distance:
            best_distance = total_distance
            best_tour = tour

    return best_tour

# Generate the expert tour using the nearest neighbor heuristic
tour = nearest_neighbor_tour(locations, use_random_restart=True, use_two_opt=True)
print("Expert Tour (node indices):", tour)  # Print the order of nodes visited by the expert heuristic

"""

```
# This is formatted as code
```

Improvements: for the training loop, we could implement a sequence to sequence training approach where each decision is based on the current state of the tour. maintain a state representation that encodes the partial tour, use a pointer network ot attention mechanism to select next city, and use the choices to guide the model."""

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# Move model and data to the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
data = data.to(device)

# Number of epochs
num_epochs = 100

# Define the target (excluding start and end)
target = torch.tensor(tour[1:-1], dtype=torch.long, device=device)

# Function to get state representation
def get_state_representation(data, visited_nodes):
    state = torch.zeros(data.num_nodes, dtype=torch.float, device=device)
    for node in visited_nodes:
        state[node] = 1
    return state

# Training loop
for epoch in range(num_epochs):
    model.train()
    optimizer.zero_grad()

    # Start with the initial node
    visited_nodes = [tour[0]]
    total_loss = 0

    for step in range(1, len(tour) - 1):
        # Get current state
        state = get_state_representation(data, visited_nodes)

        # Forward pass
        scores, _ = model(data, state)
        scores = scores.squeeze()  # shape: [num_nodes]

        # Select next node (greedy selection)
        next_node = torch.argmax(scores).item()
        visited_nodes.append(next_node)

        # Compute loss against the expert solution
        target_step = target[step - 1]
        loss = criterion(scores.unsqueeze(0), target_step.unsqueeze(0))
        total_loss += loss

        # Backward pass
        loss.backward()

    # Optimizer step after the whole tour
    optimizer.step()

    # Print loss
    if (epoch + 1) % 10 == 0:
        print(f"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss.item():.4f}")

"""Improvements: Additional heurisics that help escape local minima in the nn approach using afew techniques. These will assit in diversifying the search process and reduce the liklihood of the algorith getting stuck in suboptimal tours.


1.    random restart:The algorithm is now run 10 times with a random starting node. This can help escape local minima by diversifying the starting points and potentially finding different tour configurations.
2.   Two-Opt Heuristic: This swaps two edges in the tour and checks if it improves the total distance. If it does, the swap is applied. It iteratively tries to improve the tour by eliminating "crossed" edges.

Parameters
*   use_random_restart (default True): Enables random restarts to avoid local minima by varying the starting point.
*   use_two_opt (default True): Enables the Two-Opt heuristic to attempt improving the tour after it’s generated.

Improvements for training loop:


1.   State Representation Encoding:

2.   Dynamic Node Selection (Greedy Decoding)

3.   Step-wise Supervision with Expert Targets
4.  Score Computation Per Node
5. Modular State Representation

Improvements: decoding, explore multiple possible tours in parallel, dynamic state representation that updates as the tour is constructed, integration of the edge weights in the decision process, temperture scaling on the scores to control exploration vs exploitation.
"""

# Define a function to decode (or generate) a tour using the trained model.
# This function will use a greedy approach to select the next node with the highest score.
def decode_tour(model, data, start=0):
    model.eval()                         # Set the model to evaluation mode (disables dropout, etc.)
    num_nodes = data.x.shape[0] # Determine the total number of nodes from the data
    device = next(model.parameters()).device
    data = data.to(device)
    visited = torch.zeros(num_nodes, dtype=torch.bool, device=device)# Create a list to track visited nodes
    tour = [start]                       # Start the tour with the starting node
    visited[start] = True                # Mark the starting node as visited
    current = start                      # Set the current node to the starting node

    # Continue until all nodes are included in the tour
    while len(tour) < num_nodes:
        # Compute the scores for all nodes using the model
        scores, _ = model(data)
        scores = scores.squeeze()        # Remove extra dimensions to have a vector of scores

        # Create a mask that assigns a very low value to already visited nodes
        mask= scores.masked_fill(visited, float('-inf'))

        # Select the node with the highest score among unvisited nodes
        next_node = int(torch.argmax(mask).item())
        tour.append(next_node)           # Add the selected node to the tour
        visited[next_node] = True        # Mark the selected node as visited
        current = next_node              # Update the current node

    # Append the starting node at the end to complete the tour (returning to the start)
    tour.append(start)
    return tour

"""Improvements: Visualization, add city names to plot, color-coding segments of the tour to show progress, adding distance information."""

# Use the trained model to predict a tour
predicted_tour = decode_tour(model, data)
print("Predicted Tour (node indices):", predicted_tour)  # Print the predicted tour node indices

# Define a function to visualize the tour on a 2D plot using matplotlib.
def plot_tour(tour, locations, title="TSP Tour"):
    # Extract the latitudes for the nodes in the tour
    coords = [locations[i][1] for i in tour]  # For each node index in the tour, get its latitude
    # Extract the longitudes for the nodes in the tour
    lats, lons = zip(*coords)  # For each node index in the tour, get its longitude

    # Create a new figure with a specified size
    plt.figure(figsize=(8, 6))

    # Plot the tour as a line connecting the nodes and mark the nodes with circles
    plt.plot(lons, lats, marker='o',linestyle = '-')

    # Annotate each node with its position in the tour
    for i, node in enumerate(tour):
        # Place text near the node coordinates to show the order
        lat,lon = locations[node][1]
        plt.text(lon +0.002, lat + 0.002,str(i), fontsize=9)

    # Set the title and axis labels for the plot
    plt.title(title)
    plt.xlabel("Longitude")
    plt.ylabel("Latitude")
    plt.grid(True)                       # Enable grid lines for easier viewing
    plt.show()
    plt.tight_layout()                          # Display the plot

# Plot the tour predicted by the model
plot_tour(predicted_tour, locations, title="Predicted TSP Tour")

"""Things to note in our markdown: Improvements for each section made, what other improvements could be helpful, downfalls of TSP, comparison with other heuristics, consistency of soluctions across multiple runs."""

